# /Users/apichet/Downloads/cheetah-insurance-app/backend/routes/ollama_routes.py
# /Users/apichet/Downloads/cheetah-insurance-app/backend/routes/ollama_routes.py
from flask import Blueprint, request, jsonify, current_app
import requests
import logging
import re

ollama_bp = Blueprint("ollama", __name__)
OLLAMA_URL = "http://127.0.0.1:11434/api/generate"

def contains_fabricated_price(text: str) -> bool:
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏£‡∏≤‡∏Ñ‡∏≤‡πÅ‡∏ö‡∏ö xx,xxx ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‚Üí ‡πÉ‡∏ä‡πâ flag ‡∏ß‡πà‡∏≤‡∏≠‡∏≤‡∏à‡πÅ‡∏ï‡πà‡∏á‡∏£‡∏≤‡∏Ñ‡∏≤‡πÄ‡∏≠‡∏á
    """
    return bool(re.search(r"\b\d{1,2},\d{3}\b", text))

@ollama_bp.route("/ask-ollama", methods=["POST"])
def ask_ollama():
    try:
        data = request.get_json(force=True)
        prompt = data.get("prompt", "").strip()

        if not prompt:
            current_app.logger.warning("Received empty prompt")
            return jsonify({"error": "Missing prompt"}), 400

        current_app.logger.debug(f"üì® Prompt to Ollama: {prompt}")

        payload = {
            "model": "llama3",
            "prompt": prompt,
            "stream": False,
        }

        headers = {"Content-Type": "application/json"}
        response = requests.post(OLLAMA_URL, json=payload, headers=headers, timeout=60)
        response.raise_for_status()

        result = response.json()
        reply = result.get("response", "").strip() or "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡∏û‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ üòì"
        current_app.logger.debug(f"‚úÖ Ollama reply: {reply}")

        # üõë ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÅ‡∏ï‡πà‡∏á‡πÄ‡∏≠‡∏á
        if contains_fabricated_price(reply):
            warning_msg = "‚ö†Ô∏è Ollama ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á"
            current_app.logger.warning(warning_msg)
            return jsonify({
                "response": "Ollama ‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏ö‡∏µ‡πâ‡∏¢‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏£‡∏¥‡∏á ‚Äî ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏±‡∏ö",
                "raw_response": reply,
                "warning": "fabricated_price_detected"
            }), 200

        # ‚úÖ ‡∏ï‡∏≠‡∏ö‡∏õ‡∏Å‡∏ï‡∏¥
        return jsonify({"response": reply}), 200

    except requests.exceptions.Timeout:
        current_app.logger.error("‚è±Ô∏è Timeout while connecting to Ollama")
        return jsonify({"error": "Ollama connection timed out"}), 504

    except requests.exceptions.RequestException as req_err:
        current_app.logger.error(f"‚ùå Ollama connection error: {req_err}")
        return jsonify({"error": "Unable to reach Ollama backend"}), 503

    except Exception as e:
        current_app.logger.exception("‚ùå Internal server error")
        return jsonify({"error": "Unexpected server error"}), 500
